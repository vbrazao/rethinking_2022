---
title: "Homework - Week 8"
author: "Vasco Braz√£o"
output:
  html_document:
    keep_md: yes
  pdf_document: default
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message = FALSE, warning = FALSE}
library(rethinking)
library(tidybayes)
library(tidyverse)
library(here)


set.seed(04072022)
```

## 1

```{r one.data}
data(Achehunting)

d1 <- Achehunting %>% 
  mutate(
    success = case_when(
      kg.meat > 0 ~ 1,
      kg.meat == 0 ~ 0
    )
  ) %>% select(success, age)

```

First, just to start the foundation:

```{r one.model}
m1.1 <- ulam(
  alist(
  success ~ bernoulli(p),
  logit(p) <- a,
  a ~ normal(0, 1.5)
  ), data = d1, chains = 4, cores = 4, iter = 2000
)

precis(m1.1)
```

Now, how do we add age? I believe that the effect of age should be able to rise and fall, as people learn skills and lose them with increasing age. Maybe we can do this with a normal distribution?

```{r one.model2}
# m1.2 <- ulam(
#   alist(
#   success ~ bernoulli(p),
#   logit(p) <- a + 1/sigma*sqrt(2*3.141593)*exp(-0.5*((age-mu)/sigma)^2),
#   a ~ normal(0, 1.5),
#   mu ~ normal(30,20),
#   sigma ~ exponential(.05)
#   ), data = d1, chains = 4, cores = 4, iter = 2000
# )
# 
# precis(m1.2)
```

This just would not run and I think I know why... normals are bound super weirdly at the top! Maybe if I don't normalize?

```{r one.model3}
# m1.3 <- ulam(
#   alist(
#   success ~ bernoulli(p),
#   logit(p) <- a + maxeffect*exp(-(age-mu)^2),
#   a ~ normal(0, 1.5),
#   mu ~ normal(30,15),
#   maxeffect ~ exponential(.5)
#   ), data = d1, chains = 4, cores = 4, iter = 2000
# )
# 
# precis(m1.3)
```

However, this way there is no way for things to be more or less spread out... This is also a terrible model.

```{r one.model4}
m1.4 <- ulam(
  alist(
  success ~ bernoulli(p),
  logit(p) <- a + maxeffect*exp(-((age-mu)/spread)^2),
  a ~ normal(0, 1.5),
  mu ~ normal(30,15),
  maxeffect ~ exponential(.5),
  spread ~ exponential(.5)
  ), data = d1, chains = 4, cores = 4, iter = 2000
)

precis(m1.4)
```

Okay! This model is running terribly as well. Maybe some prior predictive simulation will at least like help? Let's simulate 100 trips per ages 11-80.

```{r one.ppsim}
dsim1 <- tibble(
  age = rep(11:80, 100),
  a = rnorm(n = 7000, mean = 0, sd = 1.5),
  mu = rnorm(n = 7000, mean = 30, sd = 15),
  maxeffect = rexp(n = 7000, .5),
  spread = rexp(n = 7000, .5),
  p = inv_logit(a + maxeffect*exp(-((age-mu)/spread)^2))
)

dsim1 %>% ggplot(aes(x = age, y = p)) +
  geom_point(alpha = .5)
```

Ok, so clearly this expects things to be all over the place...

```{r one.ppsim}
dsim2 <- tibble(
  age = rep(11:80, 100),
  a = rnorm(n = 7000, mean = 0, sd = .5),
  mu = rnorm(n = 7000, mean = 30, sd = 10),
  maxeffect = rexp(n = 7000, 1),
  spread = rexp(n = 7000, 1),
  p = inv_logit(a + maxeffect*exp(-((age-mu)/spread)^2))
)

dsim2 %>% ggplot(aes(x = age, y = p)) +
  geom_point(alpha = .5)
```

This is maybe more reasonable??

```{r one.model5}
# m1.5 <- ulam(
#   alist(
#   success ~ bernoulli(p),
#   logit(p) <- a + maxeffect*exp(-((age-mu)/spread)^2),
#   a ~ normal(0, .5),
#   mu ~ normal(30,10),
#   maxeffect ~ exponential(1),
#   spread ~ exponential(1)
#   ), data = d1, chains = 4, cores = 4, iter = 2000
# )
# 
# precis(m1.5)
```

Somehow this will take even longer to sample. Perhaps I need a new strategy.

Let's try to compare this model to our data.

```{r one.plot}
d1 %>% 
  group_by(age) %>% 
  summarise(
    prop.success = sum(success) / n()
  ) %>% 
  ggplot(aes(x = age, y = prop.success)) + geom_col()


```

Trying one last time, with some scaling that hopefully maybe will help here.

```{r one.model6}
d1.6 <- d1 %>% mutate(age = age/80)

m1.6 <- ulam(
  alist(
  success ~ bernoulli(p),
  logit(p) <- a + maxeffect*exp(-((age-mu)/spread)^2),
  a ~ normal(0, .5),
  mu ~ normal(.5,.25),
  maxeffect ~ exponential(1),
  spread ~ exponential(1)
  ), data = d1.6, chains = 4, cores = 4, iter = 2000
)

precis(m1.6)
```

```{r one.viz}
newdat <- list(
  age = (0:80)/80
)

linked1 <- link(m1.6, data = newdat)
meanprop <- apply(linked1, 2 , mean )
piprop <- apply(linked1, 2 , PI )

plotdat <- tibble(
  age = newdat$age * 80,
  mean = meanprop,
  low = piprop[1,],
  high = piprop[2,]
)

d1 %>% 
  group_by(age) %>% 
  summarise(
    prop.success = sum(success) / n()
  ) %>% 
  ggplot(aes(x = age, y = prop.success)) + 
  geom_point() +
  geom_line(data = plotdat, aes(x = age, y = mean)) +
  geom_ribbon(data = plotdat, aes(x = age, y = NULL, ymin = low, ymax = high), alpha = .7)

```

I AM INCREDULOUS. This is kind of what I expected!! Not bad but definitely not terrible. Clearly newborns do not have close to 12% chance of a successful hunt, but I am happy with how this turned out.
